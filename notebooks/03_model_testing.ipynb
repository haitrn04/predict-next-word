{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Test và Sử dụng Mô hình\n",
    "## Dự đoán từ tiếp theo - Next Word Prediction\n",
    "\n",
    "Notebook này thực hiện:\n",
    "1. Load các mô hình đã lưu (N-gram và LSTM)\n",
    "2. Load vocabulary và các file cần thiết\n",
    "3. Tạo hàm predict_next_word() như yêu cầu\n",
    "4. Test với các ví dụ cụ thể\n",
    "5. So sánh hiệu suất giữa 2 mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import thư viện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from underthesea import word_tokenize\n",
    "import os\n",
    "\n",
    "print(\"Thư viện đã được import!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Vocabulary và Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vocabulary\n",
    "print(\"Đang load vocabulary...\")\n",
    "with open('../data/processed/vocabulary.pkl', 'rb') as f:\n",
    "    vocab_data = pickle.load(f)\n",
    "    vocab = vocab_data['vocab']\n",
    "    word2idx = vocab_data['word2idx']\n",
    "    idx2word = vocab_data['idx2word']\n",
    "    vocab_size = vocab_data['vocab_size']\n",
    "\n",
    "print(f\"✓ Vocabulary loaded: {vocab_size} words\")\n",
    "\n",
    "# Load config\n",
    "with open('../data/processed/config.pkl', 'rb') as f:\n",
    "    config = pickle.load(f)\n",
    "    max_seq_len = config['max_seq_len']\n",
    "\n",
    "print(f\"✓ Config loaded: max_seq_len = {max_seq_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Models\n",
    "\n",
    "Cần import lại các class definition từ notebook 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import lại class definitions\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "# ============= N-gram Model Class =============\n",
    "class NgramModel:\n",
    "    \"\"\"\n",
    "    Mô hình N-gram được xây dựng từ đầu\n",
    "    \"\"\"\n",
    "    def __init__(self, n=3, smoothing=0.01):\n",
    "        self.n = n\n",
    "        self.smoothing = smoothing\n",
    "        self.ngram_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.context_counts = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "    \n",
    "    def get_probabilities(self, context):\n",
    "        context = tuple(context)\n",
    "        context_count = self.context_counts[context]\n",
    "        probabilities = {}\n",
    "        vocab_size = len(self.vocab)\n",
    "        \n",
    "        if context_count > 0:\n",
    "            for word in self.vocab:\n",
    "                word_count = self.ngram_counts[context].get(word, 0)\n",
    "                prob = (word_count + self.smoothing) / (context_count + self.smoothing * vocab_size)\n",
    "                probabilities[word] = prob\n",
    "        else:\n",
    "            uniform_prob = 1.0 / vocab_size\n",
    "            for word in self.vocab:\n",
    "                probabilities[word] = uniform_prob\n",
    "        \n",
    "        return probabilities\n",
    "    \n",
    "    def predict_top_k(self, context, k=5):\n",
    "        if len(context) >= self.n - 1:\n",
    "            context = context[-(self.n-1):]\n",
    "        \n",
    "        probs = self.get_probabilities(context)\n",
    "        sorted_words = sorted(probs.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        return [(word, prob) for word, prob in sorted_words[:k]]\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        model = NgramModel(n=model_data['n'], smoothing=model_data['smoothing'])\n",
    "        model.ngram_counts = defaultdict(lambda: defaultdict(int), model_data['ngram_counts'])\n",
    "        model.context_counts = defaultdict(int, model_data['context_counts'])\n",
    "        model.vocab = set(model_data['vocab'])\n",
    "        \n",
    "        return model\n",
    "\n",
    "print(\"✓ NgramModel class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= LSTM Model Class =============\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-np.clip(x, -500, 500)))\n",
    "\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=-1, keepdims=True))\n",
    "    return exp_x / np.sum(exp_x, axis=-1, keepdims=True)\n",
    "\n",
    "class SimpleLSTM:\n",
    "    \"\"\"\n",
    "    LSTM đơn giản được xây dựng từ đầu bằng NumPy\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, embedding_dim=50, hidden_dim=128, max_seq_len=10):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_seq_len = max_seq_len\n",
    "    \n",
    "    def forward_step(self, x_t, h_prev, c_prev):\n",
    "        combined = np.concatenate([x_t, h_prev], axis=1)\n",
    "        \n",
    "        ft = sigmoid(np.dot(combined, self.Wf) + self.bf)\n",
    "        it = sigmoid(np.dot(combined, self.Wi) + self.bi)\n",
    "        c_tilde = tanh(np.dot(combined, self.Wc) + self.bc)\n",
    "        c_t = ft * c_prev + it * c_tilde\n",
    "        ot = sigmoid(np.dot(combined, self.Wo) + self.bo)\n",
    "        h_t = ot * tanh(c_t)\n",
    "        \n",
    "        return h_t, c_t\n",
    "    \n",
    "    def forward(self, X):\n",
    "        batch_size = X.shape[0]\n",
    "        seq_len = X.shape[1]\n",
    "        \n",
    "        h = np.zeros((batch_size, self.hidden_dim))\n",
    "        c = np.zeros((batch_size, self.hidden_dim))\n",
    "        \n",
    "        for t in range(seq_len):\n",
    "            x_t = self.embedding[X[:, t]]\n",
    "            h, c = self.forward_step(x_t, h, c)\n",
    "        \n",
    "        logits = np.dot(h, self.Wy) + self.by\n",
    "        probs = softmax(logits)\n",
    "        \n",
    "        return probs, h\n",
    "    \n",
    "    def predict_top_k(self, X, k=5):\n",
    "        probs, _ = self.forward(X)\n",
    "        \n",
    "        top_k_indices = np.argsort(probs, axis=1)[:, -k:][:, ::-1]\n",
    "        top_k_probs = np.take_along_axis(probs, top_k_indices, axis=1)\n",
    "        \n",
    "        return top_k_indices, top_k_probs\n",
    "    \n",
    "    @staticmethod\n",
    "    def load(filepath):\n",
    "        with open(filepath, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        \n",
    "        model = SimpleLSTM(\n",
    "            vocab_size=model_data['vocab_size'],\n",
    "            embedding_dim=model_data['embedding_dim'],\n",
    "            hidden_dim=model_data['hidden_dim'],\n",
    "            max_seq_len=model_data['max_seq_len']\n",
    "        )\n",
    "        \n",
    "        model.embedding = model_data['embedding']\n",
    "        model.Wf = model_data['Wf']\n",
    "        model.bf = model_data['bf']\n",
    "        model.Wi = model_data['Wi']\n",
    "        model.bi = model_data['bi']\n",
    "        model.Wc = model_data['Wc']\n",
    "        model.bc = model_data['bc']\n",
    "        model.Wo = model_data['Wo']\n",
    "        model.bo = model_data['bo']\n",
    "        model.Wy = model_data['Wy']\n",
    "        model.by = model_data['by']\n",
    "        \n",
    "        return model\n",
    "\n",
    "print(\"✓ SimpleLSTM class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load N-gram model\n",
    "print(\"\\nĐang load N-gram model...\")\n",
    "ngram_model = NgramModel.load('../models/ngram_model.pkl')\n",
    "print(f\"✓ N-gram model loaded (n={ngram_model.n})\")\n",
    "\n",
    "# Load LSTM model\n",
    "print(\"\\nĐang load LSTM model...\")\n",
    "lstm_model = SimpleLSTM.load('../models/lstm_model.pkl')\n",
    "print(f\"✓ LSTM model loaded\")\n",
    "print(f\"  Vocab size: {lstm_model.vocab_size}\")\n",
    "print(f\"  Embedding dim: {lstm_model.embedding_dim}\")\n",
    "print(f\"  Hidden dim: {lstm_model.hidden_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Xây dựng hàm predict_next_word()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(text):\n",
    "    \"\"\"\n",
    "    Tiền xử lý input text giống như trong training\n",
    "    \"\"\"\n",
    "    import re\n",
    "    \n",
    "    # Chuyển về chữ thường\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # Loại bỏ ký tự đặc biệt không cần thiết\n",
    "    text = re.sub(r'[^a-záàảãạăắằẳẵặâấầẩẫậéèẻẽẹêếềểễệíìỉĩịóòỏõọôốồổỗộơớờởỡợúùủũụưứừửữựýỳỷỹỵđ0-9\\s]', '', text)\n",
    "    \n",
    "    # Chuẩn hóa khoảng trắng\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def tokenize_input(text):\n",
    "    \"\"\"\n",
    "    Tokenize input text\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tokens = word_tokenize(text, format=\"text\")\n",
    "        return tokens.split()\n",
    "    except:\n",
    "        return text.split()\n",
    "\n",
    "def encode_sequence(tokens, word2idx, max_len):\n",
    "    \"\"\"\n",
    "    Encode và pad sequence\n",
    "    \"\"\"\n",
    "    # Encode\n",
    "    encoded = [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
    "    \n",
    "    # Pad hoặc cắt\n",
    "    if len(encoded) < max_len:\n",
    "        padded = [word2idx['<PAD>']] * (max_len - len(encoded)) + encoded\n",
    "    else:\n",
    "        padded = encoded[-max_len:]\n",
    "    \n",
    "    return np.array(padded)\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_next_word(input_text, top_k=3, model_type='both'):\n",
    "    \"\"\"\n",
    "    Dự đoán top k từ tiếp theo\n",
    "    \n",
    "    Args:\n",
    "        input_text (str): Văn bản đầu vào\n",
    "        top_k (int): Số lượng từ dự đoán muốn trả về\n",
    "        model_type (str): 'ngram', 'lstm', hoặc 'both'\n",
    "    \n",
    "    Returns:\n",
    "        list: Danh sách các từ được dự đoán\n",
    "    \"\"\"\n",
    "    # 1. Tiền xử lý\n",
    "    cleaned_text = preprocess_input(input_text)\n",
    "    \n",
    "    # 2. Tokenize\n",
    "    tokens = tokenize_input(cleaned_text)\n",
    "    \n",
    "    if len(tokens) == 0:\n",
    "        return []\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # 3. Dự đoán với N-gram\n",
    "    if model_type in ['ngram', 'both']:\n",
    "        ngram_predictions = ngram_model.predict_top_k(tokens, k=top_k)\n",
    "        results['ngram'] = [word for word, prob in ngram_predictions]\n",
    "    \n",
    "    # 4. Dự đoán với LSTM\n",
    "    if model_type in ['lstm', 'both']:\n",
    "        # Encode sequence\n",
    "        encoded_seq = encode_sequence(tokens, word2idx, max_seq_len)\n",
    "        \n",
    "        # Reshape cho model\n",
    "        X_input = encoded_seq.reshape(1, -1)\n",
    "        \n",
    "        # Predict\n",
    "        top_k_indices, top_k_probs = lstm_model.predict_top_k(X_input, k=top_k)\n",
    "        \n",
    "        # Decode\n",
    "        lstm_predictions = [idx2word[idx] for idx in top_k_indices[0]]\n",
    "        results['lstm'] = lstm_predictions\n",
    "    \n",
    "    # 5. Trả về kết quả\n",
    "    if model_type == 'both':\n",
    "        return results\n",
    "    else:\n",
    "        return results[model_type]\n",
    "\n",
    "print(\"✓ predict_next_word() function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Test với các ví dụ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case như trong yêu cầu\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST CASE 1: tôi đi học bằng\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "input_text = \"tôi đi học bằng \"\n",
    "predictions = predict_next_word(input_text, 3, model_type='both')\n",
    "\n",
    "print(f\"\\nInput: '{input_text}'\\n\")\n",
    "print(\"N-gram predictions:\")\n",
    "print(predictions['ngram'])\n",
    "print(\"\\nLSTM predictions:\")\n",
    "print(predictions['lstm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nhiều test cases khác\n",
    "test_cases = [\n",
    "    \"tôi đi học bằng \",\n",
    "    \"hôm nay trời đẹp \",\n",
    "    \"tôi thích ăn \",\n",
    "    \"việt nam là \",\n",
    "    \"chúng tôi đang \",\n",
    "    \"anh ấy là người \",\n",
    "    \"học sinh đi \",\n",
    "    \"cô giáo dạy \"\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"NHIỀU TEST CASES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for test_input in test_cases:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Input: '{test_input}'\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # N-gram\n",
    "    ngram_preds = predict_next_word(test_input, 3, model_type='ngram')\n",
    "    print(f\"N-gram: {ngram_preds}\")\n",
    "    \n",
    "    # LSTM\n",
    "    lstm_preds = predict_next_word(test_input, 3, model_type='lstm')\n",
    "    print(f\"LSTM:   {lstm_preds}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Demo function theo format yêu cầu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function theo đúng format trong yêu cầu\n",
    "print(\"=\" * 60)\n",
    "print(\"DEMO THEO FORMAT YÊU CẦU\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Sử dụng LSTM làm mặc định\n",
    "input_example = \"tôi đi học bằng \"\n",
    "print(f\"\\ninput = \\\"{input_example}\\\"\")\n",
    "print(f\"print(predict_next_word(input, 3))\")\n",
    "\n",
    "result = predict_next_word(input_example, 3, model_type='lstm')\n",
    "print(result)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Các ví dụ khác:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "examples = [\n",
    "    (\"hôm nay trời \", 3),\n",
    "    (\"tôi thích \", 5),\n",
    "    (\"việt nam \", 3),\n",
    "]\n",
    "\n",
    "for inp, k in examples:\n",
    "    print(f\"\\ninput = \\\"{inp}\\\"\")\n",
    "    print(f\"predict_next_word(input, {k}) = {predict_next_word(inp, k, model_type='lstm')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. So sánh hiệu suất 2 mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SO SÁNH HIỆU SUẤT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_input = \"tôi đi học bằng \"\n",
    "\n",
    "# Test N-gram speed\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    _ = predict_next_word(test_input, 3, model_type='ngram')\n",
    "ngram_time = (time.time() - start) / 100\n",
    "\n",
    "# Test LSTM speed\n",
    "start = time.time()\n",
    "for _ in range(100):\n",
    "    _ = predict_next_word(test_input, 3, model_type='lstm')\n",
    "lstm_time = (time.time() - start) / 100\n",
    "\n",
    "print(f\"\\nThời gian dự đoán trung bình (100 lần):\")\n",
    "print(f\"  N-gram: {ngram_time*1000:.2f} ms\")\n",
    "print(f\"  LSTM:   {lstm_time*1000:.2f} ms\")\n",
    "print(f\"\\nN-gram nhanh hơn: {lstm_time/ngram_time:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Interactive Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive test - người dùng có thể nhập input tùy ý\n",
    "def interactive_test():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"INTERACTIVE TESTING\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Nhập văn bản để dự đoán từ tiếp theo\")\n",
    "    print(\"Nhập 'quit' để thoát\\n\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nNhập văn bản: \")\n",
    "        \n",
    "        if user_input.lower() == 'quit':\n",
    "            print(\"Tạm biệt!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            k = int(input(\"Số lượng dự đoán (k): \"))\n",
    "        except:\n",
    "            k = 3\n",
    "        \n",
    "        print(\"\\nKết quả:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # N-gram\n",
    "        ngram_result = predict_next_word(user_input, k, model_type='ngram')\n",
    "        print(f\"N-gram: {ngram_result}\")\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_result = predict_next_word(user_input, k, model_type='lstm')\n",
    "        print(f\"LSTM:   {lstm_result}\")\n",
    "\n",
    "# Uncomment để chạy interactive mode\n",
    "# interactive_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Tổng kết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"TỔNG KẾT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\n✓ Đã load thành công:\")\n",
    "print(f\"  - Vocabulary: {vocab_size} từ\")\n",
    "print(f\"  - N-gram model: {ngram_model.n}-gram\")\n",
    "print(f\"  - LSTM model: {lstm_model.embedding_dim}D embeddings, {lstm_model.hidden_dim}D hidden\")\n",
    "\n",
    "print(\"\\n✓ Các hàm đã tạo:\")\n",
    "print(\"  - predict_next_word(input_text, top_k, model_type)\")\n",
    "print(\"    + input_text: Văn bản đầu vào\")\n",
    "print(\"    + top_k: Số lượng từ dự đoán (mặc định 3)\")\n",
    "print(\"    + model_type: 'ngram', 'lstm', hoặc 'both' (mặc định 'both')\")\n",
    "\n",
    "print(\"\\n✓ Cách sử dụng:\")\n",
    "print('  input = \"tôi đi học bằng \"')\n",
    "print('  predictions = predict_next_word(input, 3, model_type=\"lstm\")')\n",
    "print('  print(predictions)')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"HOÀN THÀNH!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nHệ thống dự đoán từ tiếp theo đã sẵn sàng sử dụng!\")\n",
    "print(\"\\nMô hình:\")\n",
    "print(\"  1. N-gram (Trigram): Dựa trên thống kê n-gram\")\n",
    "print(\"  2. LSTM: Mạng neural tự xây dựng từ NumPy\")\n",
    "print(\"\\nCả 2 mô hình đều được xây dựng từ đầu không sử dụng\")\n",
    "print(\"sklearn, PyTorch, hay TensorFlow như yêu cầu!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
