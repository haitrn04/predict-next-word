{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 1: Tiá»n xá»­ lÃ½ vÃ  Chuáº©n bá»‹ Dá»¯ liá»‡u (PhiÃªn báº£n NÃ¢ng cao)\n",
    "## Dá»± Ä‘oÃ¡n tá»« tiáº¿p theo - Next Word Prediction\n",
    "\n",
    "Notebook nÃ y thá»±c hiá»‡n:\n",
    "1. Táº£i dá»¯ liá»‡u tá»« VTSNLP dataset (10,000 dÃ²ng)\n",
    "2. Tiá»n xá»­ lÃ½ vÄƒn báº£n theo cáº¥u trÃºc phÃ¢n cáº¥p: **VÄƒn báº£n â†’ Äoáº¡n vÄƒn â†’ CÃ¢u â†’ Tá»«/Cá»¥m tá»«**\n",
    "3. Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t vÃ  lÃ m sáº¡ch dá»¯ liá»‡u ká»¹ lÆ°á»¡ng\n",
    "4. Tokenization vá»›i underthesea\n",
    "5. XÃ¢y dá»±ng vocabulary vÃ  encoding\n",
    "6. LÆ°u dá»¯ liá»‡u Ä‘Ã£ tiá»n xá»­ lÃ½"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import thÆ° viá»‡n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CÃ i Ä‘áº·t cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t\n",
    "# !pip install datasets underthesea numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\thanh\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThÆ° viá»‡n Ä‘Ã£ Ä‘Æ°á»£c import thÃ nh cÃ´ng!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from underthesea import word_tokenize, sent_tokenize\n",
    "from collections import Counter, defaultdict\n",
    "import os\n",
    "\n",
    "print(\"ThÆ° viá»‡n Ä‘Ã£ Ä‘Æ°á»£c import thÃ nh cÃ´ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Táº£i dá»¯ liá»‡u tá»« VTSNLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Äang táº£i dá»¯ liá»‡u tá»« VTSNLP...\n",
      "Dataset Ä‘Ã£ táº£i: DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'id', 'domain'],\n",
      "        num_rows: 12169131\n",
      "    })\n",
      "})\n",
      "\n",
      "Cáº¥u trÃºc: {'text': Value('string'), 'id': Value('string'), 'domain': Value('string')}\n"
     ]
    }
   ],
   "source": [
    "# Táº£i dataset\n",
    "print(\"Äang táº£i dá»¯ liá»‡u tá»« VTSNLP...\")\n",
    "ds = load_dataset(\"VTSNLP/vietnamese_curated_dataset\")\n",
    "print(f\"Dataset Ä‘Ã£ táº£i: {ds}\")\n",
    "print(f\"\\nCáº¥u trÃºc: {ds['train'].features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sá»‘ lÆ°á»£ng máº«u: 500000\n",
      "\n",
      "VÃ­ dá»¥ máº«u Ä‘áº§u tiÃªn:\n",
      "Internet Society hay ISOC lÃ  má»™t tá»• chá»©c quá»‘c táº¿ hoáº¡t Ä‘á»™ng phi lá»£i nhuáº­n, phi chÃ­nh phá»§ vÃ  bao gá»“m cÃ¡c thÃ nh viÃªn cÃ³ trÃ¬nh Ä‘á»™ chuyÃªn ngÃ nh. Tá»• chá»©c nÃ y chÃº trá»ng Ä‘áº¿n: tiÃªu chuáº©n, giÃ¡o dá»¥c vÃ  cÃ¡c váº¥n Ä‘á» vá» chÃ­nh sÃ¡ch. Vá»›i trÃªn 145 tá»• chá»©c thÃ nh viÃªn vÃ  65.000 thÃ nh viÃªn cÃ¡ nhÃ¢n, ISOC bao gá»“m nhá»¯ng co\n"
     ]
    }
   ],
   "source": [
    "# Láº¥y 10,000 dÃ²ng dá»¯ liá»‡u\n",
    "NUM_SAMPLES = 500000\n",
    "train_data = ds['train'].select(range(min(NUM_SAMPLES, len(ds['train']))))\n",
    "\n",
    "print(f\"Sá»‘ lÆ°á»£ng máº«u: {len(train_data)}\")\n",
    "print(f\"\\nVÃ­ dá»¥ máº«u Ä‘áº§u tiÃªn:\")\n",
    "print(train_data[0]['text'][:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÄÃ£ trÃ­ch xuáº¥t 500000 vÄƒn báº£n\n"
     ]
    }
   ],
   "source": [
    "# TrÃ­ch xuáº¥t vÄƒn báº£n\n",
    "texts = []\n",
    "for item in train_data:\n",
    "    if 'text' in item:\n",
    "        texts.append(item['text'])\n",
    "    elif 'content' in item:\n",
    "        texts.append(item['content'])\n",
    "    elif 'sentence' in item:\n",
    "        texts.append(item['sentence'])\n",
    "\n",
    "print(f\"ÄÃ£ trÃ­ch xuáº¥t {len(texts)} vÄƒn báº£n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tiá»n xá»­ lÃ½ vÄƒn báº£n - Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST HÃ€M CLEAN TEXT\n",
      "============================================================\n",
      "\n",
      "TrÆ°á»›c: Xin chÃ o!!! ÄÃ¢y lÃ  VÃ Dá»¤ 123... http://example.com\n",
      "Sau:  xin chÃ o! Ä‘Ã¢y lÃ  vÃ­ dá»¥.\n",
      "\n",
      "TrÆ°á»›c: Email: test@email.com, SÄT: 0912345678\n",
      "Sau:  email: sÄ‘t:\n",
      "\n",
      "TrÆ°á»›c: NÄƒm   2024...   Viá»‡t Nam!!!!\n",
      "Sau:  nÄƒm. viá»‡t nam!\n",
      "\n",
      "TrÆ°á»›c: GiÃ¡    100,000Ä‘ -- khuyáº¿n mÃ£i 50%\n",
      "Sau:  giÃ¡, 000Ä‘ - khuyáº¿n mÃ£i\n"
     ]
    }
   ],
   "source": [
    "def clean_text_advanced(text):\n",
    "    \"\"\"\n",
    "    LÃ m sáº¡ch vÄƒn báº£n nÃ¢ng cao:\n",
    "    - Loáº¡i bá» URL, email, sá»‘ Ä‘iá»‡n thoáº¡i\n",
    "    - Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t khÃ´ng cáº§n thiáº¿t\n",
    "    - Loáº¡i bá» sá»‘ Ä‘á»©ng riÃªng\n",
    "    - Chuáº©n hÃ³a dáº¥u cÃ¢u\n",
    "    - Chuáº©n hÃ³a khoáº£ng tráº¯ng\n",
    "    - Chuyá»ƒn vá» chá»¯ thÆ°á»ng\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Chuyá»ƒn vá» chá»¯ thÆ°á»ng\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Loáº¡i bá» URL\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # Loáº¡i bá» email\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    \n",
    "    # Loáº¡i bá» sá»‘ Ä‘iá»‡n thoáº¡i (dáº¡ng 0xxx-xxx-xxx hoáº·c 0xxxxxxxxx)\n",
    "    text = re.sub(r'\\b0\\d{9,10}\\b', '', text)\n",
    "    text = re.sub(r'\\b\\d{3}[-.]\\d{3}[-.]\\d{4}\\b', '', text)\n",
    "    \n",
    "    # Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘áº·c biá»‡t, chá»‰ giá»¯:\n",
    "    # - Chá»¯ cÃ¡i tiáº¿ng Viá»‡t (cÃ³ dáº¥u)\n",
    "    # - Sá»‘ (sáº½ lá»c riÃªng sau)\n",
    "    # - Dáº¥u cÃ¢u cÆ¡ báº£n: . , ! ? ; :\n",
    "    text = re.sub(\n",
    "        r'[^a-zÃ¡Ã áº£Ã£áº¡Äƒáº¯áº±áº³áºµáº·Ã¢áº¥áº§áº©áº«áº­Ã©Ã¨áº»áº½áº¹Ãªáº¿á»á»ƒá»…á»‡Ã­Ã¬á»‰Ä©á»‹Ã³Ã²á»Ãµá»Ã´á»‘á»“á»•á»—á»™Æ¡á»›á»á»Ÿá»¡á»£ÃºÃ¹á»§Å©á»¥Æ°á»©á»«á»­á»¯á»±Ã½á»³á»·á»¹á»µÄ‘0-9\\s.,!?;:\\-]',\n",
    "        '',\n",
    "        text\n",
    "    )\n",
    "    \n",
    "    # Loáº¡i bá» sá»‘ Ä‘á»©ng riÃªng (khÃ´ng pháº£i lÃ  pháº§n cá»§a tá»«)\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    \n",
    "    # Loáº¡i bá» cÃ¡c kÃ½ tá»± Ä‘Æ¡n láº» (trá»« cÃ¡c tá»« cÃ³ nghÄ©a nhÆ° \"á»Ÿ\", \"Ã½\", \"Ã¡\")\n",
    "    # text = re.sub(r'\\b[a-z]\\b', '', text)\n",
    "    \n",
    "    # Chuáº©n hÃ³a dáº¥u cÃ¢u - loáº¡i bá» dáº¥u cÃ¢u trÃ¹ng láº·p\n",
    "    text = re.sub(r'\\.{2,}', '.', text)  # ... -> .\n",
    "    text = re.sub(r',{2,}', ',', text)   # ,, -> ,\n",
    "    text = re.sub(r'!{2,}', '!', text)   # !! -> !\n",
    "    text = re.sub(r'\\?{2,}', '?', text)  # ?? -> ?\n",
    "    text = re.sub(r';{2,}', ';', text)   # ;; -> ;\n",
    "    text = re.sub(r':{2,}', ':', text)   # :: -> :\n",
    "    text = re.sub(r'-{2,}', '-', text)   # -- -> -\n",
    "    \n",
    "    # Chuáº©n hÃ³a khoáº£ng tráº¯ng\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Loáº¡i bá» khoáº£ng tráº¯ng trÆ°á»›c dáº¥u cÃ¢u\n",
    "    text = re.sub(r'\\s+([.,!?;:])', r'\\1', text)\n",
    "    \n",
    "    # ThÃªm khoáº£ng tráº¯ng sau dáº¥u cÃ¢u náº¿u chÆ°a cÃ³\n",
    "    text = re.sub(r'([.,!?;:])([^\\s])', r'\\1 \\2', text)\n",
    "    \n",
    "    # Loáº¡i bá» khoáº£ng tráº¯ng á»Ÿ Ä‘áº§u vÃ  cuá»‘i\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Loáº¡i bá» dáº¥u cÃ¢u á»Ÿ Ä‘áº§u cÃ¢u\n",
    "    text = re.sub(r'^[.,!?;:\\-]+', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Test hÃ m clean_text_advanced\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST HÃ€M CLEAN TEXT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "test_samples = [\n",
    "    \"Xin chÃ o!!! ÄÃ¢y lÃ  VÃ Dá»¤ 123... http://example.com\",\n",
    "    \"Email: test@email.com, SÄT: 0912345678\",\n",
    "    \"NÄƒm   2024...   Viá»‡t Nam!!!!\",\n",
    "    \"GiÃ¡    100,000Ä‘ -- khuyáº¿n mÃ£i 50%\"\n",
    "]\n",
    "\n",
    "for sample in test_samples:\n",
    "    cleaned = clean_text_advanced(sample)\n",
    "    print(f\"\\nTrÆ°á»›c: {sample}\")\n",
    "    print(f\"Sau:  {cleaned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Äang lÃ m sáº¡ch dá»¯ liá»‡u...\n",
      "ÄÃ£ xá»­ lÃ½ 0/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 1000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 2000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 3000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 4000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 5000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 6000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 7000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 8000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 9000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 10000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 11000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 12000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 13000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 14000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 15000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 16000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 17000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 18000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 19000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 20000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 21000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 22000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 23000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 24000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 25000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 26000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 27000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 28000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 29000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 30000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 31000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 32000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 33000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 34000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 35000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 36000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 37000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 38000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 39000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 40000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 41000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 42000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 43000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 44000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 45000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 46000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 47000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 48000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 49000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 50000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 51000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 52000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 53000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 54000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 55000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 56000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 57000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 58000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 59000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 60000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 61000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 62000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 63000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 64000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 65000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 66000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 67000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 68000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 69000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 70000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 71000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 72000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 73000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 74000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 75000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 76000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 77000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 78000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 79000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 80000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 81000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 82000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 83000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 84000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 85000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 86000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 87000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 88000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 89000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 90000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 91000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 92000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 93000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 94000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 95000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 96000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 97000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 98000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 99000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 100000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 101000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 102000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 103000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 104000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 105000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 106000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 107000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 108000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 109000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 110000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 111000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 112000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 113000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 114000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 115000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 116000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 117000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 118000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 119000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 120000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 121000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 122000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 123000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 124000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 125000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 126000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 127000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 128000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 129000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 130000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 131000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 132000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 133000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 134000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 135000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 136000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 137000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 138000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 139000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 140000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 141000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 142000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 143000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 144000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 145000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 146000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 147000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 148000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 149000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 150000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 151000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 152000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 153000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 154000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 155000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 156000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 157000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 158000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 159000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 160000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 161000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 162000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 163000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 164000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 165000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 166000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 167000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 168000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 169000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 170000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 171000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 172000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 173000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 174000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 175000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 176000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 177000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 178000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 179000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 180000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 181000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 182000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 183000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 184000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 185000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 186000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 187000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 188000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 189000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 190000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 191000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 192000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 193000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 194000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 195000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 196000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 197000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 198000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 199000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 200000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 201000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 202000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 203000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 204000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 205000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 206000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 207000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 208000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 209000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 210000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 211000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 212000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 213000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 214000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 215000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 216000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 217000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 218000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 219000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 220000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 221000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 222000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 223000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 224000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 225000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 226000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 227000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 228000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 229000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 230000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 231000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 232000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 233000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 234000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 235000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 236000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 237000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 238000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 239000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 240000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 241000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 242000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 243000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 244000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 245000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 246000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 247000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 248000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 249000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 250000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 251000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 252000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 253000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 254000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 255000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 256000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 257000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 258000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 259000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 260000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 261000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 262000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 263000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 264000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 265000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 266000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 267000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 268000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 269000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 270000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 271000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 272000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 273000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 274000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 275000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 276000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 277000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 278000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 279000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 280000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 281000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 282000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 283000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 284000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 285000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 286000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 287000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 288000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 289000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 290000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 291000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 292000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 293000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 294000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 295000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 296000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 297000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 298000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 299000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 300000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 301000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 302000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 303000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 304000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 305000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 306000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 307000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 308000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 309000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 310000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 311000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 312000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 313000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 314000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 315000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 316000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 317000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 318000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 319000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 320000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 321000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 322000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 323000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 324000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 325000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 326000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 327000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 328000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 329000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 330000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 331000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 332000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 333000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 334000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 335000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 336000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 337000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 338000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 339000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 340000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 341000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 342000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 343000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 344000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 345000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 346000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 347000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 348000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 349000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 350000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 351000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 352000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 353000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 354000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 355000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 356000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 357000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 358000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 359000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 360000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 361000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 362000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 363000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 364000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 365000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 366000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 367000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 368000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 369000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 370000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 371000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 372000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 373000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 374000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 375000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 376000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 377000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 378000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 379000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 380000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 381000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 382000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 383000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 384000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 385000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 386000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 387000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 388000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 389000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 390000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 391000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 392000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 393000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 394000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 395000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 396000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 397000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 398000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 399000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 400000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 401000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 402000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 403000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 404000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 405000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 406000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 407000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 408000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 409000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 410000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 411000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 412000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 413000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 414000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 415000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 416000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 417000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 418000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 419000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 420000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 421000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 422000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 423000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 424000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 425000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 426000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 427000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 428000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 429000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 430000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 431000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 432000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 433000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 434000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 435000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 436000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 437000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 438000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 439000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 440000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 441000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 442000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 443000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 444000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 445000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 446000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 447000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 448000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 449000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 450000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 451000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 452000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 453000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 454000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 455000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 456000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 457000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 458000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 459000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 460000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 461000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 462000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 463000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 464000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 465000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 466000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 467000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 468000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 469000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 470000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 471000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 472000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 473000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 474000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 475000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 476000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 477000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 478000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 479000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 480000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 481000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 482000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 483000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 484000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 485000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 486000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 487000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 488000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 489000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 490000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 491000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 492000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 493000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 494000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 495000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 496000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 497000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 498000/500000 vÄƒn báº£n\n",
      "ÄÃ£ xá»­ lÃ½ 499000/500000 vÄƒn báº£n\n",
      "\n",
      "Sá»‘ vÄƒn báº£n sau khi lÃ m sáº¡ch: 499997\n",
      "\n",
      "VÃ­ dá»¥ vÄƒn báº£n sau khi lÃ m sáº¡ch:\n",
      "internet society hay isoc lÃ  má»™t tá»• chá»©c quá»‘c táº¿ hoáº¡t Ä‘á»™ng phi lá»£i nhuáº­n, phi chÃ­nh phá»§ vÃ  bao gá»“m cÃ¡c thÃ nh viÃªn cÃ³ trÃ¬nh Ä‘á»™ chuyÃªn ngÃ nh. tá»• chá»©c nÃ y chÃº trá»ng Ä‘áº¿n: tiÃªu chuáº©n, giÃ¡o dá»¥c vÃ  cÃ¡c váº¥n Ä‘á» vá» chÃ­nh sÃ¡ch. vá»›i trÃªn tá»• chá»©c thÃ nh viÃªn vÃ . thÃ nh viÃªn cÃ¡ nhÃ¢n, isoc bao gá»“m nhá»¯ng con ngÆ°á»i cá»¥\n"
     ]
    }
   ],
   "source": [
    "# LÃ m sáº¡ch toÃ n bá»™ dá»¯ liá»‡u\n",
    "print(\"\\nÄang lÃ m sáº¡ch dá»¯ liá»‡u...\")\n",
    "cleaned_texts = []\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"ÄÃ£ xá»­ lÃ½ {i}/{len(texts)} vÄƒn báº£n\")\n",
    "    \n",
    "    cleaned = clean_text_advanced(text)\n",
    "    # Chá»‰ giá»¯ vÄƒn báº£n cÃ³ Ä‘á»™ dÃ i >= 10 kÃ½ tá»±\n",
    "    if len(cleaned) >= 10:\n",
    "        cleaned_texts.append(cleaned)\n",
    "\n",
    "print(f\"\\nSá»‘ vÄƒn báº£n sau khi lÃ m sáº¡ch: {len(cleaned_texts)}\")\n",
    "print(f\"\\nVÃ­ dá»¥ vÄƒn báº£n sau khi lÃ m sáº¡ch:\")\n",
    "print(cleaned_texts[0][:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Xá»­ lÃ½ phÃ¢n cáº¥p: VÄƒn báº£n â†’ Äoáº¡n vÄƒn â†’ CÃ¢u â†’ Tá»«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TEST Xá»¬ LÃ PHÃ‚N Cáº¤P\n",
      "============================================================\n",
      "\n",
      "Sá»‘ Ä‘oáº¡n vÄƒn: 3\n",
      "Äoáº¡n 1: ÄÃ¢y lÃ  Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn. NÃ³ cÃ³ nhiá»u cÃ¢u.\n",
      "Äoáº¡n 2: ÄÃ¢y lÃ  Ä‘oáº¡n vÄƒn thá»© hai. TÃ´i Ä‘i há»c báº±ng xe buÃ½t. HÃ´m nay trá»i Ä‘áº¹p.\n",
      "Äoáº¡n 3: Äoáº¡n vÄƒn cuá»‘i cÃ¹ng.\n",
      "\n",
      "\n",
      "TÃ¡ch cÃ¢u tá»« Ä‘oáº¡n 1:\n",
      "CÃ¢u 1: ÄÃ¢y lÃ  Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn.\n",
      "CÃ¢u 2: NÃ³ cÃ³ nhiá»u cÃ¢u.\n",
      "\n",
      "\n",
      "Tokenize cÃ¢u 1:\n",
      "Tokens: ['ÄÃ¢y', 'lÃ ', 'Ä‘oáº¡n', 'vÄƒn', 'Ä‘áº§u_tiÃªn', '.']\n"
     ]
    }
   ],
   "source": [
    "def split_into_paragraphs(text):\n",
    "    \"\"\"\n",
    "    TÃ¡ch vÄƒn báº£n thÃ nh cÃ¡c Ä‘oáº¡n vÄƒn\n",
    "    Äoáº¡n vÄƒn Ä‘Æ°á»£c phÃ¢n tÃ¡ch bá»Ÿi xuá»‘ng dÃ²ng (\\n)\n",
    "    \"\"\"\n",
    "    # TÃ¡ch theo dáº¥u xuá»‘ng dÃ²ng\n",
    "    paragraphs = text.split('\\n')\n",
    "    \n",
    "    # Loáº¡i bá» Ä‘oáº¡n vÄƒn rá»—ng\n",
    "    paragraphs = [p.strip() for p in paragraphs if p.strip()]\n",
    "    \n",
    "    return paragraphs\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"\n",
    "    TÃ¡ch vÄƒn báº£n/Ä‘oáº¡n vÄƒn thÃ nh cÃ¡c cÃ¢u\n",
    "    Sá»­ dá»¥ng sent_tokenize cá»§a underthesea\n",
    "    \"\"\"\n",
    "    try:\n",
    "        sentences = sent_tokenize(text)\n",
    "        # Loáº¡i bá» cÃ¢u rá»—ng vÃ  quÃ¡ ngáº¯n (< 5 kÃ½ tá»±)\n",
    "        sentences = [s.strip() for s in sentences if len(s.strip()) >= 5]\n",
    "        return sentences\n",
    "    except:\n",
    "        # Náº¿u lá»—i, tÃ¡ch Ä‘Æ¡n giáº£n báº±ng dáº¥u cÃ¢u\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        return [s.strip() for s in sentences if len(s.strip()) >= 5]\n",
    "\n",
    "def tokenize_sentence(sentence):\n",
    "    \"\"\"\n",
    "    TÃ¡ch cÃ¢u thÃ nh cÃ¡c tá»«/cá»¥m tá»«\n",
    "    Sá»­ dá»¥ng word_tokenize cá»§a underthesea\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tokens = word_tokenize(sentence, format=\"text\")\n",
    "        return tokens.split()\n",
    "    except:\n",
    "        # Náº¿u lá»—i, dÃ¹ng split Ä‘Æ¡n giáº£n\n",
    "        return sentence.split()\n",
    "\n",
    "# Test cÃ¡c hÃ m phÃ¢n cáº¥p\n",
    "print(\"=\" * 60)\n",
    "print(\"TEST Xá»¬ LÃ PHÃ‚N Cáº¤P\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "sample_text = \"\"\"ÄÃ¢y lÃ  Ä‘oáº¡n vÄƒn Ä‘áº§u tiÃªn. NÃ³ cÃ³ nhiá»u cÃ¢u.\n",
    "\n",
    "ÄÃ¢y lÃ  Ä‘oáº¡n vÄƒn thá»© hai. TÃ´i Ä‘i há»c báº±ng xe buÃ½t. HÃ´m nay trá»i Ä‘áº¹p.\n",
    "\n",
    "Äoáº¡n vÄƒn cuá»‘i cÃ¹ng.\"\"\"\n",
    "\n",
    "# TÃ¡ch Ä‘oáº¡n vÄƒn\n",
    "paragraphs = split_into_paragraphs(sample_text)\n",
    "print(f\"\\nSá»‘ Ä‘oáº¡n vÄƒn: {len(paragraphs)}\")\n",
    "for i, para in enumerate(paragraphs, 1):\n",
    "    print(f\"Äoáº¡n {i}: {para}\")\n",
    "\n",
    "# TÃ¡ch cÃ¢u tá»« Ä‘oáº¡n Ä‘áº§u tiÃªn\n",
    "print(f\"\\n\\nTÃ¡ch cÃ¢u tá»« Ä‘oáº¡n 1:\")\n",
    "sentences = split_into_sentences(paragraphs[0])\n",
    "for i, sent in enumerate(sentences, 1):\n",
    "    print(f\"CÃ¢u {i}: {sent}\")\n",
    "\n",
    "# Tokenize cÃ¢u Ä‘áº§u tiÃªn\n",
    "if sentences:\n",
    "    print(f\"\\n\\nTokenize cÃ¢u 1:\")\n",
    "    tokens = tokenize_sentence(sentences[0])\n",
    "    print(f\"Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Xá»¬ LÃ TOÃ€N Bá»˜ Dá»® LIá»†U THEO Cáº¤U TRÃšC PHÃ‚N Cáº¤P\n",
      "============================================================\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 0/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 1000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 2000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 3000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 4000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 5000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 6000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 7000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 8000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 9000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 10000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 11000/499997...\n",
      "Äang xá»­ lÃ½ vÄƒn báº£n 12000/499997...\n"
     ]
    }
   ],
   "source": [
    "# Xá»­ lÃ½ toÃ n bá»™ dá»¯ liá»‡u theo cáº¥u trÃºc phÃ¢n cáº¥p\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Xá»¬ LÃ TOÃ€N Bá»˜ Dá»® LIá»†U THEO Cáº¤U TRÃšC PHÃ‚N Cáº¤P\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_sentences = []\n",
    "all_tokens = []\n",
    "\n",
    "for i, text in enumerate(cleaned_texts):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Äang xá»­ lÃ½ vÄƒn báº£n {i}/{len(cleaned_texts)}...\")\n",
    "    \n",
    "    # BÆ°á»›c 1: TÃ¡ch thÃ nh Ä‘oáº¡n vÄƒn\n",
    "    paragraphs = split_into_paragraphs(text)\n",
    "    \n",
    "    # BÆ°á»›c 2: TÃ¡ch má»—i Ä‘oáº¡n vÄƒn thÃ nh cÃ¢u\n",
    "    for paragraph in paragraphs:\n",
    "        sentences = split_into_sentences(paragraph)\n",
    "        \n",
    "        # BÆ°á»›c 3: Tokenize má»—i cÃ¢u thÃ nh tá»«/cá»¥m tá»«\n",
    "        for sentence in sentences:\n",
    "            tokens = tokenize_sentence(sentence)\n",
    "            \n",
    "            # Loáº¡i bá» cÃ¡c token lÃ  dáº¥u cÃ¢u Ä‘Æ¡n thuáº§n\n",
    "            tokens = [t for t in tokens if not re.match(r'^[.,!?;:\\-]+$', t)]\n",
    "            \n",
    "            # Chá»‰ giá»¯ cÃ¢u cÃ³ Ã­t nháº¥t 3 tá»«\n",
    "            if len(tokens) >= 3:\n",
    "                all_sentences.append(sentence)\n",
    "                all_tokens.append(tokens)\n",
    "\n",
    "print(f\"\\nTá»•ng sá»‘ cÃ¢u: {len(all_sentences)}\")\n",
    "print(f\"Tá»•ng sá»‘ sequences tokens: {len(all_tokens)}\")\n",
    "print(f\"\\nVÃ­ dá»¥ 5 cÃ¢u Ä‘áº§u tiÃªn:\")\n",
    "for i in range(min(5, len(all_sentences))):\n",
    "    print(f\"\\nCÃ¢u {i+1}: {all_sentences[i]}\")\n",
    "    print(f\"Tokens: {all_tokens[i][:15]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. XÃ¢y dá»±ng Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Äáº¿m táº§n suáº¥t tá»«\n",
    "print(\"Äang Ä‘áº¿m táº§n suáº¥t tá»«...\")\n",
    "word_counts = Counter()\n",
    "\n",
    "for tokens in all_tokens:\n",
    "    word_counts.update(tokens)\n",
    "\n",
    "print(f\"\\nTá»•ng sá»‘ tá»« duy nháº¥t: {len(word_counts)}\")\n",
    "print(f\"\\n15 tá»« phá»• biáº¿n nháº¥t:\")\n",
    "for word, count in word_counts.most_common(15):\n",
    "    print(f\"  {word}: {count}\")\n",
    "\n",
    "print(f\"\\n15 tá»« Ã­t phá»• biáº¿n nháº¥t (xuáº¥t hiá»‡n 1 láº§n):\")\n",
    "rare_words = [(w, c) for w, c in word_counts.items() if c == 1]\n",
    "print(f\"Sá»‘ tá»« xuáº¥t hiá»‡n 1 láº§n: {len(rare_words)}\")\n",
    "for word, count in list(rare_words)[:15]:\n",
    "    print(f\"  {word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o vocabulary - chá»‰ giá»¯ cÃ¡c tá»« xuáº¥t hiá»‡n Ã­t nháº¥t MIN_WORD_FREQ láº§n\n",
    "MIN_WORD_FREQ = 2\n",
    "vocab = ['<PAD>', '<UNK>', '<START>', '<END>']  # Special tokens\n",
    "\n",
    "# ThÃªm cÃ¡c tá»« cÃ³ táº§n suáº¥t >= MIN_WORD_FREQ\n",
    "for word, count in word_counts.most_common():\n",
    "    if count >= MIN_WORD_FREQ:\n",
    "        vocab.append(word)\n",
    "\n",
    "print(f\"\\nKÃ­ch thÆ°á»›c vocabulary (min_freq={MIN_WORD_FREQ}): {len(vocab)}\")\n",
    "\n",
    "# Táº¡o mapping word <-> index\n",
    "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "print(f\"\\nVÃ­ dá»¥ word2idx:\")\n",
    "test_words = ['<PAD>', '<UNK>', 'tÃ´i', 'lÃ ', 'Ä‘i', 'há»c', 'viá»‡t_nam']\n",
    "for word in test_words:\n",
    "    if word in word2idx:\n",
    "        print(f\"  {word}: {word2idx[word]}\")\n",
    "    else:\n",
    "        print(f\"  {word}: <NOT IN VOCAB>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Encoding vÃ  táº¡o Training Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_tokens(tokens, word2idx):\n",
    "    \"\"\"\n",
    "    Chuyá»ƒn Ä‘á»•i tokens thÃ nh sequence of indices\n",
    "    \"\"\"\n",
    "    return [word2idx.get(token, word2idx['<UNK>']) for token in tokens]\n",
    "\n",
    "# Encode toÃ n bá»™ dá»¯ liá»‡u\n",
    "print(\"Äang encode dá»¯ liá»‡u...\")\n",
    "encoded_sequences = []\n",
    "\n",
    "for tokens in all_tokens:\n",
    "    encoded = encode_tokens(tokens, word2idx)\n",
    "    if len(encoded) >= 3:  # Cáº§n Ã­t nháº¥t 3 tá»«\n",
    "        encoded_sequences.append(encoded)\n",
    "\n",
    "print(f\"Sá»‘ sequences Ä‘Ã£ encode: {len(encoded_sequences)}\")\n",
    "print(f\"\\nVÃ­ dá»¥:\")\n",
    "print(f\"Tokens: {all_tokens[0][:10]}\")\n",
    "print(f\"Encoded: {encoded_sequences[0][:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_sequences(encoded_sequences, max_sequence_len=10):\n",
    "    \"\"\"\n",
    "    Táº¡o cÃ¡c cáº·p (input_sequence, next_word) cho training\n",
    "    \"\"\"\n",
    "    input_sequences = []\n",
    "    \n",
    "    for encoded_seq in encoded_sequences:\n",
    "        for i in range(1, len(encoded_seq)):\n",
    "            n = min(i, max_sequence_len)\n",
    "            input_seq = encoded_seq[i-n:i]\n",
    "            target_word = encoded_seq[i]\n",
    "            input_sequences.append((input_seq, target_word))\n",
    "    \n",
    "    return input_sequences\n",
    "\n",
    "# Táº¡o training sequences\n",
    "MAX_SEQ_LEN = 10\n",
    "print(f\"\\nÄang táº¡o training sequences (max_len={MAX_SEQ_LEN})...\")\n",
    "training_sequences = create_training_sequences(encoded_sequences, MAX_SEQ_LEN)\n",
    "\n",
    "print(f\"Tá»•ng sá»‘ training pairs: {len(training_sequences)}\")\n",
    "print(f\"\\nVÃ­ dá»¥ 5 sequences:\")\n",
    "for i in range(min(5, len(training_sequences))):\n",
    "    seq, target = training_sequences[i]\n",
    "    seq_words = [idx2word[idx] for idx in seq]\n",
    "    target_word = idx2word[target]\n",
    "    print(f\"  {seq_words} -> {target_word}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequences, max_len, pad_value=0):\n",
    "    \"\"\"\n",
    "    Padding sequences vá» cÃ¹ng Ä‘á»™ dÃ i\n",
    "    \"\"\"\n",
    "    padded = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_len:\n",
    "            padded_seq = [pad_value] * (max_len - len(seq)) + seq\n",
    "        else:\n",
    "            padded_seq = seq[-max_len:]\n",
    "        padded.append(padded_seq)\n",
    "    return np.array(padded)\n",
    "\n",
    "# TÃ¡ch input vÃ  target\n",
    "X_sequences = [seq for seq, _ in training_sequences]\n",
    "y_targets = np.array([target for _, target in training_sequences])\n",
    "\n",
    "# Padding\n",
    "X_padded = pad_sequences(X_sequences, MAX_SEQ_LEN, pad_value=word2idx['<PAD>'])\n",
    "\n",
    "print(f\"Shape cá»§a X: {X_padded.shape}\")\n",
    "print(f\"Shape cá»§a y: {y_targets.shape}\")\n",
    "print(f\"\\nVÃ­ dá»¥ sau khi padding:\")\n",
    "print(f\"X[0]: {X_padded[0]}\")\n",
    "print(f\"y[0]: {y_targets[0]} ({idx2word[y_targets[0]]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Thá»‘ng kÃª dá»¯ liá»‡u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"THá»NG KÃŠ Dá»® LIá»†U SAU TIá»€N Xá»¬ LÃ (PHIÃŠN Báº¢N NÃ‚NG CAO)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nğŸ“ Dá»¯ liá»‡u gá»‘c:\")\n",
    "print(f\"  - Sá»‘ vÄƒn báº£n ban Ä‘áº§u: {len(texts)}\")\n",
    "print(f\"  - Sá»‘ vÄƒn báº£n sau lÃ m sáº¡ch: {len(cleaned_texts)}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Xá»­ lÃ½ phÃ¢n cáº¥p:\")\n",
    "print(f\"  - Tá»•ng sá»‘ cÃ¢u: {len(all_sentences)}\")\n",
    "print(f\"  - Tá»•ng sá»‘ sequences tokens: {len(all_tokens)}\")\n",
    "print(f\"  - Trung bÃ¬nh {len(all_tokens)/len(cleaned_texts):.1f} cÃ¢u/vÄƒn báº£n\")\n",
    "\n",
    "print(f\"\\nğŸ“– Vocabulary:\")\n",
    "print(f\"  - Tá»•ng sá»‘ tá»« duy nháº¥t: {len(word_counts)}\")\n",
    "print(f\"  - KÃ­ch thÆ°á»›c vocabulary (min_freq={MIN_WORD_FREQ}): {len(vocab)}\")\n",
    "print(f\"  - Tá»· lá»‡ giá»¯ láº¡i: {len(vocab)/len(word_counts)*100:.1f}%\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Training data:\")\n",
    "print(f\"  - Sá»‘ sequences Ä‘Ã£ encode: {len(encoded_sequences)}\")\n",
    "print(f\"  - Tá»•ng sá»‘ training pairs: {len(training_sequences)}\")\n",
    "print(f\"  - Max sequence length: {MAX_SEQ_LEN}\")\n",
    "\n",
    "print(f\"\\nğŸ“¦ Shape cá»§a dá»¯ liá»‡u:\")\n",
    "print(f\"  - X shape: {X_padded.shape}\")\n",
    "print(f\"  - y shape: {y_targets.shape}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. LÆ°u dá»¯ liá»‡u Ä‘Ã£ tiá»n xá»­ lÃ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Táº¡o thÆ° má»¥c\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "\n",
    "print(\"Äang lÆ°u dá»¯ liá»‡u...\")\n",
    "\n",
    "# 1. Vocabulary\n",
    "with open('../data/processed/vocabulary.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'vocab': vocab,\n",
    "        'word2idx': word2idx,\n",
    "        'idx2word': idx2word,\n",
    "        'vocab_size': len(vocab),\n",
    "        'word_counts': dict(word_counts.most_common(1000))  # Top 1000 tá»«\n",
    "    }, f)\n",
    "print(\"âœ“ ÄÃ£ lÆ°u vocabulary.pkl\")\n",
    "\n",
    "# 2. Training data\n",
    "with open('../data/processed/training_data.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'X': X_padded,\n",
    "        'y': y_targets,\n",
    "        'max_seq_len': MAX_SEQ_LEN\n",
    "    }, f)\n",
    "print(\"âœ“ ÄÃ£ lÆ°u training_data.pkl\")\n",
    "\n",
    "# 3. Tokenized texts (cho n-gram)\n",
    "with open('../data/processed/tokenized_texts.pkl', 'wb') as f:\n",
    "    pickle.dump(all_tokens, f)\n",
    "print(\"âœ“ ÄÃ£ lÆ°u tokenized_texts.pkl\")\n",
    "\n",
    "# 4. Sentences (cho phÃ¢n tÃ­ch)\n",
    "with open('../data/processed/sentences.pkl', 'wb') as f:\n",
    "    pickle.dump(all_sentences[:10000], f)  # LÆ°u 10000 cÃ¢u Ä‘áº§u\n",
    "print(\"âœ“ ÄÃ£ lÆ°u sentences.pkl\")\n",
    "\n",
    "# 5. Config\n",
    "config = {\n",
    "    'num_documents': len(texts),\n",
    "    'num_cleaned_documents': len(cleaned_texts),\n",
    "    'num_sentences': len(all_sentences),\n",
    "    'num_sequences': len(all_tokens),\n",
    "    'vocab_size': len(vocab),\n",
    "    'max_seq_len': MAX_SEQ_LEN,\n",
    "    'min_word_freq': MIN_WORD_FREQ,\n",
    "    'num_training_pairs': len(training_sequences),\n",
    "    'preprocessing_method': 'hierarchical',  # VÄƒn báº£n -> Äoáº¡n -> CÃ¢u -> Tá»«\n",
    "}\n",
    "with open('../data/processed/config.pkl', 'wb') as f:\n",
    "    pickle.dump(config, f)\n",
    "print(\"âœ“ ÄÃ£ lÆ°u config.pkl\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"HOÃ€N THÃ€NH TIá»€N Xá»¬ LÃ Dá»® LIá»†U (PHIÃŠN Báº¢N NÃ‚NG CAO)!\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nâœ… ÄÃ£ thá»±c hiá»‡n:\")\n",
    "print(\"  1. Loáº¡i bá» kÃ½ tá»± Ä‘áº·c biá»‡t ká»¹ lÆ°á»¡ng\")\n",
    "print(\"  2. Xá»­ lÃ½ phÃ¢n cáº¥p: VÄƒn báº£n â†’ Äoáº¡n vÄƒn â†’ CÃ¢u â†’ Tá»«/Cá»¥m tá»«\")\n",
    "print(\"  3. Tokenization vá»›i underthesea\")\n",
    "print(\"  4. XÃ¢y dá»±ng vocabulary vá»›i filtering\")\n",
    "print(\"  5. Encoding vÃ  padding sequences\")\n",
    "print(\"\\nğŸ“ CÃ¡c file Ä‘Ã£ lÆ°u trong: ../data/processed/\")\n",
    "print(\"  - vocabulary.pkl\")\n",
    "print(\"  - training_data.pkl\")\n",
    "print(\"  - tokenized_texts.pkl\")\n",
    "print(\"  - sentences.pkl\")\n",
    "print(\"  - config.pkl\")\n",
    "print(\"\\nâ¡ï¸  Báº¡n cÃ³ thá»ƒ chuyá»ƒn sang notebook 02 Ä‘á»ƒ training mÃ´ hÃ¬nh!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
